{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bases possíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crisa\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mvp = pd.read_csv('Bases\\\\creditcard.csv')\n",
    "df_mvp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos que serão analisados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f1, gmean, pr_auc, auc\n",
    "\n",
    "classe()\n",
    "\n",
    "retorno -> metrica"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(DONE) * Lightgbm       - Algorítimico \n",
    "(DONE) * Smote          - Preprocessing\n",
    "\n",
    "- Vini\n",
    "* CDBH           - Híbrido\n",
    "* OSM Classifier - Algorítimico \n",
    "* SVM VR         - Preprocessing\n",
    "* DBSMOTE        - Preprocessing\n",
    "\n",
    "\n",
    "- Manaus\n",
    "* HDDT Emsemble  - Algorítimico\n",
    "* WHMBoost       - Cost Sensitivity\n",
    "* CHMDT          - Cost Sensitivity \n",
    "* CCR            - Preprocessing\n",
    "* EHSO           - Preprocessing\n",
    "\n",
    "(DONE) * EasyEmsemble   - Algorítimico\n",
    "* Método novo    - Algorítimico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline padrão para Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, LabelBinarizer, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitxy(dataframe : pd.DataFrame, y : str = 'target'):\n",
    "    X = dataframe.drop(labels = [y], axis = 1)\n",
    "    y = dataframe[y]\n",
    "    \n",
    "    return(X, y)\n",
    "\n",
    "\n",
    "def train_test_val(X: pd.DataFrame, y: pd.Series):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42, stratify = y_train)\n",
    "    \n",
    "    return(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "\n",
    "def create_prep_pipe(dataframe : pd.DataFrame, target_column : str) -> (sklearn.pipeline.FeatureUnion, pd.Series, pd.Series):\n",
    "    dataframe = dataframe.drop(labels = [target_column], axis = 1)\n",
    "    num_cols = dataframe.select_dtypes(include=[float, int]).columns\n",
    "    cat_cols = dataframe.select_dtypes(include=[object, pd.datetime]).columns\n",
    "    \n",
    "    if num_cols.values.shape[0] > 0:\n",
    "        pipe_num = Pipeline(\n",
    "        steps = [\n",
    "            (\"selector_num\", ColumnTransformer([(\"selector\", \"passthrough\", num_cols.values)], remainder = 'drop')),\n",
    "            ('num_imputer', SimpleImputer(strategy='mean'))\n",
    "        ])\n",
    "    else:\n",
    "        pipe_num = None\n",
    "        \n",
    "    if cat_cols.values.shape[0] > 0:\n",
    "        pipe_cat = Pipeline(\n",
    "        steps = [\n",
    "            (\"selector_cat\", ColumnTransformer([(\"selector\", \"passthrough\", cat_cols.values)], remainder = 'drop')),\n",
    "            (\"OrdinalEnc\", OrdinalEncoder(handle_unknown = \"use_encoded_value\", unknown_value = -1)),\n",
    "            ('cat_imputer', SimpleImputer(strategy='constant', fill_value='None'))\n",
    "        ])        \n",
    "    else:\n",
    "        pipe_cat = None\n",
    "       \n",
    "    if pipe_num is not None and pipe_cat is not None:\n",
    "        prep_feat = FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('num_pipe', pipe_num),\n",
    "            ('cat_pipe', pipe_cat)\n",
    "            \n",
    "        ], verbose = False)  \n",
    "        \n",
    "        return (prep_feat, num_cols.values, cat_cols.values)\n",
    "\n",
    "    if pipe_num is not None and pipe_cat is None:\n",
    "        prep_feat = FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('num_pipe', pipe_num)\n",
    "            \n",
    "        ], verbose = False)\n",
    "        \n",
    "        return (prep_feat, num_cols.values, [])\n",
    "\n",
    "    if pipe_num is None and pipe_cat is not None:\n",
    "        prep_feat = FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('cat_pipe', pipe_cat)\n",
    "            \n",
    "        ], verbose = False) \n",
    "        \n",
    "        return (prep_feat, [], cat_cols.values)\n",
    "\n",
    "\n",
    "def plot_dist(y_train, pred_proba_train, y_val, pred_proba_val):\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (16,6))\n",
    "    plt.subplots_adjust(left = None, right = None, top = None, bottom = None, wspace = 0.2, hspace = 0.4)\n",
    "    \n",
    "    vis = pd.DataFrame()\n",
    "    vis['target'] = y_train\n",
    "    vis['proba'] = pred_proba_train\n",
    "    \n",
    "    list_1 = vis[vis.target == 1].proba\n",
    "    list_2 = vis[vis.target == 0].proba\n",
    "    \n",
    "    sns.distplot(list_1, kde = True, ax = axs[0], hist = True, bins = 100)\n",
    "    sns.distplot(list_2, kde = True, ax = axs[0], hist = True, bins = 100)\n",
    "    \n",
    "    axs[0].set_title('train Thereshold Curve')\n",
    "    \n",
    "    \n",
    "    \n",
    "    vis = pd.DataFrame()\n",
    "    vis['target'] = y_val\n",
    "    vis['proba'] = pred_proba_val\n",
    "    \n",
    "    list_1 = vis[vis.target == 1].proba\n",
    "    list_2 = vis[vis.target == 0].proba\n",
    "    \n",
    "    sns.distplot(list_1, kde = True, ax = axs[1], hist = True, bins = 100)\n",
    "    sns.distplot(list_2, kde = True, ax = axs[1], hist = True, bins = 100)\n",
    "    \n",
    "    axs[1].set_title('valid Thereshold Curve')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tcc_lgbm():\n",
    "    def __init__(self, dataframe : pd.DataFrame, target: str, metric : str = 'average_precision', pipe_final : sklearn.pipeline = None):\n",
    "        self.dataframe = dataframe\n",
    "        self.target = target\n",
    "        self.metric = metric\n",
    "        self._pipe_final = pipe_final\n",
    "    \n",
    "    def fit(self):\n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)\n",
    "    \n",
    "        prep_feat_tuple = create_prep_pipe(self.dataframe, self.target)\n",
    "        prep_feat = prep_feat_tuple[0]\n",
    "    \n",
    "        lists_pandarizer = list(prep_feat_tuple[1]) + list(prep_feat_tuple[2])\n",
    "        \n",
    "        LGBM = LGBMClassifier(random_state = 42, n_jobs = -1)\n",
    "\n",
    "        pipe_tuning = Pipeline([\n",
    "            ('transformer_prep', prep_feat),\n",
    "            (\"pandarizer\", FunctionTransformer(lambda x: pd.DataFrame(x, columns = lists_pandarizer))),\n",
    "            ('estimator', LGBM)\n",
    "        ])\n",
    "        \n",
    "        pipe_prep = Pipeline([\n",
    "            ('transformer_prep', prep_feat),\n",
    "            (\"pandarizer\", FunctionTransformer(lambda x: pd.DataFrame(x, columns = lists_pandarizer))),\n",
    "        ])\n",
    "        pipe_prep.fit(X_train)       \n",
    "        \n",
    "        cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.3, random_state = 42)\n",
    "        \n",
    "        metric = self.metric\n",
    "        \n",
    "        fit_params = {\n",
    "            'eval_metric': metric, \n",
    "            'eval_set': [(X_test, pd.DataFrame(y_test))],\n",
    "            'callbacks': [(early_stopping(stopping_rounds = 10, verbose = True))],\n",
    "        }        \n",
    "        \n",
    "        LGBM_search_space = {\n",
    "            \"estimator__learning_rate\": Real(0.001, 0.01, prior = 'log-uniform'),\n",
    "            \"estimator__n_estimators\": Integer(100, 1000),\n",
    "            \"estimator__class_weight\": Categorical(['balanced', None]),\n",
    "            \"estimator__num_leaves\": Integer(32, 256),\n",
    "            \"estimator__min_child_samples\": Integer(100, 1000),\n",
    "            \"estimator__reg_alpha\": Real(0, 100, prior = 'uniform'),\n",
    "            \"estimator__reg_lambda\": Real(10., 200., prior = 'uniform'),\n",
    "            \"estimator__objective\": Categorical(['binary']),\n",
    "            \"estimator__importance_type\":Categorical(['gain']),\n",
    "            \"estimator__boosting_type\": Categorical(['goss'])\n",
    "        }    \n",
    "        \n",
    "        LGBM_bayes_search = BayesSearchCV(pipe_tuning, LGBM_search_space, n_iter = 2, scoring = metric, \n",
    "                                         return_train_score = True, \n",
    "                                         fit_params = fit_params,\n",
    "                                         n_jobs = -1, cv = cv, random_state = 42, optimizer_kwargs = {'base_estimator': 'GP'})\n",
    "        \n",
    "        \n",
    "        LGBM_bayes_search.fit(X_train, y_train)        \n",
    "        \n",
    "        results_cv = pd.DataFrame(LGBM_bayes_search.cv_results_)\n",
    "        \n",
    "        temp = results_cv[['mean_train_score', 'mean_test_score']]\n",
    "        temp['diff'] = temp['mean_test_score'] - temp['mean_train_score']\n",
    "        to_go = temp[abs(temp['diff']) < 0.05].sort_values(by = 'mean_test_score', ascending = False).head(1).index\n",
    "        \n",
    "        params = results_cv.loc[to_go.values[0]]\n",
    "        kwargs = params.params   \n",
    "        print(kwargs)\n",
    "        \n",
    "        best_LGBM = LGBMClassifier(random_state = 42, n_jobs = -1, verbose = -1, **kwargs)\n",
    "        \n",
    "        best_LGBM.fit(pipe_prep.transform(X_train), y_train, early_stopping_rounds = 10, verbose = 20, eval_metric = metric,\n",
    "                     eval_set = [(pipe_prep.transform(X_test), y_test)]) \n",
    "        \n",
    "        \n",
    "        pipe_final = Pipeline(\n",
    "        [\n",
    "            ('pipe_transformer_prep', pipe_prep),\n",
    "            ('pipe_estimator', best_LGBM)\n",
    "        ])       \n",
    "        \n",
    "        self._pipe_final = pipe_final\n",
    "        \n",
    "    def predict_proba(self, who : str = 'val'):\n",
    "        if self._pipe_final is None:\n",
    "            return None\n",
    "        \n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)        \n",
    "        \n",
    "        dic = {'val': X_val, \n",
    "              'test': X_test,\n",
    "              'train': X_train}\n",
    "        y_score = self._pipe_final.predict_proba(dic[who])[:,1]\n",
    "        return y_score\n",
    "    \n",
    "    def get_metric(self, who : str = 'val'):\n",
    "        if self._pipe_final is None:\n",
    "            return None\n",
    "        \n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)\n",
    "        \n",
    "        dic_x = {'val': X_val, \n",
    "              'test': X_test,\n",
    "              'train': X_train}\n",
    "\n",
    "        dic_y = {'val': y_val, \n",
    "              'test': y_test,\n",
    "              'train': y_train}\n",
    "        \n",
    "        \n",
    "        y_score = self._pipe_final.predict_proba(dic_x[who])[:,1]\n",
    "        average_precision = average_precision_score(dic_y[who], y_score)\n",
    "        return average_precision\n",
    "    \n",
    "    \n",
    "    def plot_dist(self):\n",
    "        if self._pipe_final is None:\n",
    "            return None        \n",
    "\n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)        \n",
    "        \n",
    "        y_score_train = self._pipe_final.predict_proba(X_train)[:,1]\n",
    "        y_score_val = self._pipe_final.predict_proba(X_val)[:,1]\n",
    "        \n",
    "        plot_dist(y_train, y_score_train, y_val, y_score_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_lgbm = tcc_lgbm(df_mvp, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('estimator__boosting_type', 'goss'), ('estimator__class_weight', None), ('estimator__importance_type', 'gain'), ('estimator__learning_rate', 0.002069186296126171), ('estimator__min_child_samples', 703), ('estimator__n_estimators', 473), ('estimator__num_leaves', 111), ('estimator__objective', 'binary'), ('estimator__reg_alpha', 30.44633110365062), ('estimator__reg_lambda', 133.08040178590676)])\n"
     ]
    }
   ],
   "source": [
    "temp_lgbm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pipe_transformer_prep&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;transformer_prep&#x27;,\n",
       "                                  FeatureUnion(transformer_list=[(&#x27;num_pipe&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;selector_num&#x27;,\n",
       "                                                                                   ColumnTransformer(transformers=[(&#x27;selector&#x27;,\n",
       "                                                                                                                    &#x27;passthrough&#x27;,\n",
       "                                                                                                                    array([&#x27;Time&#x27;, &#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
       "       &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;,\n",
       "       &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V2...\n",
       "                 LGBMClassifier(estimator__boosting_type=&#x27;goss&#x27;,\n",
       "                                estimator__class_weight=None,\n",
       "                                estimator__importance_type=&#x27;gain&#x27;,\n",
       "                                estimator__learning_rate=0.002069186296126171,\n",
       "                                estimator__min_child_samples=703,\n",
       "                                estimator__n_estimators=473,\n",
       "                                estimator__num_leaves=111,\n",
       "                                estimator__objective=&#x27;binary&#x27;,\n",
       "                                estimator__reg_alpha=30.44633110365062,\n",
       "                                estimator__reg_lambda=133.08040178590676,\n",
       "                                random_state=42, verbose=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pipe_transformer_prep&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;transformer_prep&#x27;,\n",
       "                                  FeatureUnion(transformer_list=[(&#x27;num_pipe&#x27;,\n",
       "                                                                  Pipeline(steps=[(&#x27;selector_num&#x27;,\n",
       "                                                                                   ColumnTransformer(transformers=[(&#x27;selector&#x27;,\n",
       "                                                                                                                    &#x27;passthrough&#x27;,\n",
       "                                                                                                                    array([&#x27;Time&#x27;, &#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
       "       &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;,\n",
       "       &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V2...\n",
       "                 LGBMClassifier(estimator__boosting_type=&#x27;goss&#x27;,\n",
       "                                estimator__class_weight=None,\n",
       "                                estimator__importance_type=&#x27;gain&#x27;,\n",
       "                                estimator__learning_rate=0.002069186296126171,\n",
       "                                estimator__min_child_samples=703,\n",
       "                                estimator__n_estimators=473,\n",
       "                                estimator__num_leaves=111,\n",
       "                                estimator__objective=&#x27;binary&#x27;,\n",
       "                                estimator__reg_alpha=30.44633110365062,\n",
       "                                estimator__reg_lambda=133.08040178590676,\n",
       "                                random_state=42, verbose=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipe_transformer_prep: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transformer_prep&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;num_pipe&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;selector_num&#x27;,\n",
       "                                                                  ColumnTransformer(transformers=[(&#x27;selector&#x27;,\n",
       "                                                                                                   &#x27;passthrough&#x27;,\n",
       "                                                                                                   array([&#x27;Time&#x27;, &#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
       "       &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;,\n",
       "       &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
       "       &#x27;V28&#x27;, &#x27;Amount&#x27;], dtype=object))])),\n",
       "                                                                 (&#x27;num_imputer&#x27;,\n",
       "                                                                  SimpleImputer())]))])),\n",
       "                (&#x27;pandarizer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function tcc_lgbm.fit.&lt;locals&gt;.&lt;lambda&gt; at 0x00000181A5C0B550&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer_prep: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;num_pipe&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;selector_num&#x27;,\n",
       "                                                 ColumnTransformer(transformers=[(&#x27;selector&#x27;,\n",
       "                                                                                  &#x27;passthrough&#x27;,\n",
       "                                                                                  array([&#x27;Time&#x27;, &#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
       "       &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;,\n",
       "       &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
       "       &#x27;V28&#x27;, &#x27;Amount&#x27;], dtype=object))])),\n",
       "                                                (&#x27;num_imputer&#x27;,\n",
       "                                                 SimpleImputer())]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>num_pipe</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">selector_num: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;selector&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 array([&#x27;Time&#x27;, &#x27;V1&#x27;, &#x27;V2&#x27;, &#x27;V3&#x27;, &#x27;V4&#x27;, &#x27;V5&#x27;, &#x27;V6&#x27;, &#x27;V7&#x27;, &#x27;V8&#x27;, &#x27;V9&#x27;,\n",
       "       &#x27;V10&#x27;, &#x27;V11&#x27;, &#x27;V12&#x27;, &#x27;V13&#x27;, &#x27;V14&#x27;, &#x27;V15&#x27;, &#x27;V16&#x27;, &#x27;V17&#x27;, &#x27;V18&#x27;,\n",
       "       &#x27;V19&#x27;, &#x27;V20&#x27;, &#x27;V21&#x27;, &#x27;V22&#x27;, &#x27;V23&#x27;, &#x27;V24&#x27;, &#x27;V25&#x27;, &#x27;V26&#x27;, &#x27;V27&#x27;,\n",
       "       &#x27;V28&#x27;, &#x27;Amount&#x27;], dtype=object))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">selector</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Time&#x27; &#x27;V1&#x27; &#x27;V2&#x27; &#x27;V3&#x27; &#x27;V4&#x27; &#x27;V5&#x27; &#x27;V6&#x27; &#x27;V7&#x27; &#x27;V8&#x27; &#x27;V9&#x27; &#x27;V10&#x27; &#x27;V11&#x27; &#x27;V12&#x27;\n",
       " &#x27;V13&#x27; &#x27;V14&#x27; &#x27;V15&#x27; &#x27;V16&#x27; &#x27;V17&#x27; &#x27;V18&#x27; &#x27;V19&#x27; &#x27;V20&#x27; &#x27;V21&#x27; &#x27;V22&#x27; &#x27;V23&#x27; &#x27;V24&#x27;\n",
       " &#x27;V25&#x27; &#x27;V26&#x27; &#x27;V27&#x27; &#x27;V28&#x27; &#x27;Amount&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function tcc_lgbm.fit.&lt;locals&gt;.&lt;lambda&gt; at 0x00000181A5C0B550&gt;)</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(estimator__boosting_type=&#x27;goss&#x27;, estimator__class_weight=None,\n",
       "               estimator__importance_type=&#x27;gain&#x27;,\n",
       "               estimator__learning_rate=0.002069186296126171,\n",
       "               estimator__min_child_samples=703, estimator__n_estimators=473,\n",
       "               estimator__num_leaves=111, estimator__objective=&#x27;binary&#x27;,\n",
       "               estimator__reg_alpha=30.44633110365062,\n",
       "               estimator__reg_lambda=133.08040178590676, random_state=42,\n",
       "               verbose=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pipe_transformer_prep',\n",
       "                 Pipeline(steps=[('transformer_prep',\n",
       "                                  FeatureUnion(transformer_list=[('num_pipe',\n",
       "                                                                  Pipeline(steps=[('selector_num',\n",
       "                                                                                   ColumnTransformer(transformers=[('selector',\n",
       "                                                                                                                    'passthrough',\n",
       "                                                                                                                    array(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',\n",
       "       'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
       "       'V19', 'V20', 'V21', 'V22', 'V2...\n",
       "                 LGBMClassifier(estimator__boosting_type='goss',\n",
       "                                estimator__class_weight=None,\n",
       "                                estimator__importance_type='gain',\n",
       "                                estimator__learning_rate=0.002069186296126171,\n",
       "                                estimator__min_child_samples=703,\n",
       "                                estimator__n_estimators=473,\n",
       "                                estimator__num_leaves=111,\n",
       "                                estimator__objective='binary',\n",
       "                                estimator__reg_alpha=30.44633110365062,\n",
       "                                estimator__reg_lambda=133.08040178590676,\n",
       "                                random_state=42, verbose=-1))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_lgbm._pipe_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00157184, 0.00157184, 0.00157675, ..., 0.00157184, 0.00157184,\n",
       "       0.00157184])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_lgbm.predict_proba(who = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8712203126285343, 0.7368724168176575, 0.773486477188228]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[temp_lgbm.get_metric(who = 'train'), temp_lgbm.get_metric(who = 'test'), temp_lgbm.get_metric(who = 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09773383544030623"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_lgbm.get_metric(who = 'train') - temp_lgbm.get_metric(who = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_lgbm.plot_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Padrão para SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, LabelBinarizer, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitxy(dataframe : pd.DataFrame, y : str = 'target'):\n",
    "    X = dataframe.drop(labels = [y], axis = 1)\n",
    "    y = dataframe[y]\n",
    "    \n",
    "    return(X, y)\n",
    "\n",
    "\n",
    "def train_test_val(X: pd.DataFrame, y: pd.Series):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42, stratify = y_train)\n",
    "    \n",
    "    return(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "\n",
    "\n",
    "def create_prep_pipe(dataframe : pd.DataFrame, target_column : str) -> (sklearn.pipeline.FeatureUnion, pd.Series, pd.Series):\n",
    "    dataframe = dataframe.drop(labels = [target_column], axis = 1)\n",
    "    num_cols = dataframe.select_dtypes(include=[float, int]).columns\n",
    "    cat_cols = dataframe.select_dtypes(include=[object, pd.datetime]).columns\n",
    "    \n",
    "    if num_cols.values.shape[0] > 0:\n",
    "        pipe_num = Pipeline(\n",
    "        steps = [\n",
    "            (\"selector_num\", ColumnTransformer([(\"selector\", \"passthrough\", num_cols.values)], remainder = 'drop')),\n",
    "            ('num_imputer', SimpleImputer(strategy='mean'))\n",
    "        ])\n",
    "    else:\n",
    "        pipe_num = None\n",
    "        \n",
    "    if cat_cols.values.shape[0] > 0:\n",
    "        pipe_cat = Pipeline(\n",
    "        steps = [\n",
    "            (\"selector_cat\", ColumnTransformer([(\"selector\", \"passthrough\", cat_cols.values)], remainder = 'drop')),\n",
    "            (\"OrdinalEnc\", OrdinalEncoder(handle_unknown = \"use_encoded_value\", unknown_value = -1)),\n",
    "            ('cat_imputer', SimpleImputer(strategy='constant', fill_value='None'))\n",
    "        ])        \n",
    "    else:\n",
    "        pipe_cat = None\n",
    "       \n",
    "    if pipe_num is not None and pipe_cat is not None:\n",
    "        prep_feat = FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('num_pipe', pipe_num),\n",
    "            ('cat_pipe', pipe_cat)\n",
    "            \n",
    "        ], verbose = False)  \n",
    "        \n",
    "        return (prep_feat, num_cols.values, cat_cols.values)\n",
    "\n",
    "    if pipe_num is not None and pipe_cat is None:\n",
    "        prep_feat = FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('num_pipe', pipe_num)\n",
    "            \n",
    "        ], verbose = False)\n",
    "        \n",
    "        return (prep_feat, num_cols.values, [])\n",
    "\n",
    "    if pipe_num is None and pipe_cat is not None:\n",
    "        prep_feat = FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('cat_pipe', pipe_cat)\n",
    "            \n",
    "        ], verbose = False) \n",
    "        \n",
    "        return (prep_feat, [], cat_cols.values)\n",
    "\n",
    "\n",
    "def plot_dist(y_train, pred_proba_train, y_val, pred_proba_val):\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (16,6))\n",
    "    plt.subplots_adjust(left = None, right = None, top = None, bottom = None, wspace = 0.2, hspace = 0.4)\n",
    "    \n",
    "    vis = pd.DataFrame()\n",
    "    vis['target'] = y_train\n",
    "    vis['proba'] = pred_proba_train\n",
    "    \n",
    "    list_1 = vis[vis.target == 1].proba\n",
    "    list_2 = vis[vis.target == 0].proba\n",
    "    \n",
    "    sns.distplot(list_1, kde = True, ax = axs[0], hist = True, bins = 100)\n",
    "    sns.distplot(list_2, kde = True, ax = axs[0], hist = True, bins = 100)\n",
    "    \n",
    "    axs[0].set_title('train Thereshold Curve')\n",
    "    \n",
    "    \n",
    "    \n",
    "    vis = pd.DataFrame()\n",
    "    vis['target'] = y_val\n",
    "    vis['proba'] = pred_proba_val\n",
    "    \n",
    "    list_1 = vis[vis.target == 1].proba\n",
    "    list_2 = vis[vis.target == 0].proba\n",
    "    \n",
    "    sns.distplot(list_1, kde = True, ax = axs[1], hist = True, bins = 100)\n",
    "    sns.distplot(list_2, kde = True, ax = axs[1], hist = True, bins = 100)\n",
    "    \n",
    "    axs[1].set_title('valid Thereshold Curve')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tcc_smote():\n",
    "    def __init__(self, dataframe : pd.DataFrame, target: str, metric : str = 'average_precision', pipe_final : sklearn.pipeline = None):\n",
    "        self.dataframe = dataframe\n",
    "        self.target = target\n",
    "        self.metric = metric\n",
    "        self._pipe_final = pipe_final\n",
    "    \n",
    "    def fit(self):\n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)\n",
    "    \n",
    "        prep_feat_tuple = create_prep_pipe(self.dataframe, self.target)\n",
    "        prep_feat = prep_feat_tuple[0]\n",
    "    \n",
    "        lists_pandarizer = list(prep_feat_tuple[1]) + list(prep_feat_tuple[2])\n",
    "        \n",
    "        LGBM = LGBMClassifier(random_state = 42, n_jobs = -1)\n",
    "  \n",
    "        pipe_prep = Pipeline([\n",
    "            ('transformer_prep', prep_feat),\n",
    "            (\"pandarizer\", FunctionTransformer(lambda x: pd.DataFrame(x, columns = lists_pandarizer))),\n",
    "        ])\n",
    "        pipe_prep.fit(X_train)       \n",
    "     \n",
    "\n",
    "        metric = self.metric\n",
    "        \n",
    "        RF_estimator = RandomForestClassifier(random_state= 42)\n",
    "        \n",
    "        smote = SMOTE()\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(pipe_prep.transform(X_train), y_train)\n",
    "        RF_estimator.fit(X_train_smote, y_train_smote) \n",
    "        \n",
    "        \n",
    "        pipe_final = Pipeline(\n",
    "        [\n",
    "            ('pipe_transformer_prep', pipe_prep),\n",
    "            ('pipe_estimator', RF_estimator)\n",
    "        ])       \n",
    "        \n",
    "        self._pipe_final = pipe_final\n",
    "        \n",
    "    def predict_proba(self, who : str = 'val'):\n",
    "        if self._pipe_final is None:\n",
    "            return None\n",
    "        \n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)        \n",
    "        \n",
    "        dic = {'val': X_val, \n",
    "              'test': X_test,\n",
    "              'train': X_train}\n",
    "        y_score = self._pipe_final.predict_proba(dic[who])[:,1]\n",
    "        return y_score\n",
    "    \n",
    "    def get_metric(self, who : str = 'val'):\n",
    "        if self._pipe_final is None:\n",
    "            return None\n",
    "        \n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)\n",
    "        \n",
    "        dic_x = {'val': X_val, \n",
    "              'test': X_test,\n",
    "              'train': X_train}\n",
    "\n",
    "        dic_y = {'val': y_val, \n",
    "              'test': y_test,\n",
    "              'train': y_train}\n",
    "        \n",
    "        \n",
    "        y_score = self._pipe_final.predict_proba(dic_x[who])[:,1]\n",
    "        average_precision = average_precision_score(dic_y[who], y_score)\n",
    "        return average_precision\n",
    "    \n",
    "    \n",
    "    def plot_dist(self):\n",
    "        if self._pipe_final is None:\n",
    "            return None        \n",
    "\n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)        \n",
    "        \n",
    "        y_score_train = self._pipe_final.predict_proba(X_train)[:,1]\n",
    "        y_score_val = self._pipe_final.predict_proba(X_val)[:,1]\n",
    "        \n",
    "        plot_dist(y_train, y_score_train, y_val, y_score_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_smote = tcc_smote(df_mvp, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_smote.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_smote._pipe_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_smote.predict_proba(who = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[temp_smote.get_metric(who = 'train'), temp_smote.get_metric(who = 'test'), temp_smote.get_metric(who = 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_smote.get_metric(who = 'train') - temp_smote.get_metric(who = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_smote.plot_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDDT Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import operator\n",
    "\n",
    "\n",
    "class HDDT(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    HDDT (Hellinger Distance Decision Tree).\n",
    "    References\n",
    "    ----------\n",
    "    ..[1]   David A. Cieslak, T. Ryan Hoens, Nitesh V. Chawla and W. Philip Kegelmeyer, Data Min Knowl Disc 2011\n",
    "            https://www3.nd.edu/~dial/papers/DMKD11.pdf\n",
    "    ..[2]   Learning Decision Trees for Unbalanced Data, David A. Cieslak and Nitesh V. Chawla, ECML 2008\n",
    "            https://www3.nd.edu/~dial/papers/ECML08.pdf\n",
    "    ..[3]   Implementation of the HDDT in R programming language\n",
    "            https://github.com/kaurao/HDDT\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C=9):\n",
    "        # TODO: grid search - for the best C\n",
    "        # C=2 - for all\n",
    "        # C=9 - for real streams\n",
    "        self.C = C\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fitting.\"\"\"\n",
    "        self.partial_fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y, classes=None):\n",
    "        if type(y) is not np.ndarray:\n",
    "            y = np.array(y)\n",
    "        # Check classes\n",
    "        self.classes_ = classes\n",
    "        if self.classes_ is None:\n",
    "            self.classes_, _ = np.unique(y, return_inverse=True)\n",
    "\n",
    "        self.labels = np.unique(y)\n",
    "\n",
    "        # Check if is continuous or discrete\n",
    "        self.n_features = X.shape[1]\n",
    "        self.features_type = []\n",
    "        for f in range(self.n_features):\n",
    "            if isinstance(X[0,f], float):\n",
    "                self.features_type.append(\"continuous\")\n",
    "            else:\n",
    "                self.features_type.append(\"discrete\")\n",
    "\n",
    "        self.root = self.HDDT_func(X, y, self.C)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_row = X.shape[0]\n",
    "        y = np.full(n_row, -1)\n",
    "        for i in range(n_row):\n",
    "            # search the tree until we find a leaf node\n",
    "            node = self.root\n",
    "            while isinstance(node.get(\"v\"), (int, float)):\n",
    "                if node[\"type\"] == \"discrete\":\n",
    "                    if X[i,node[\"i\"]] == node[\"v\"]:\n",
    "                        node = node[\"childLeft\"]\n",
    "                    else:\n",
    "                        node = node[\"childRight\"]\n",
    "\n",
    "                elif node[\"type\"] == \"continuous\":\n",
    "                    if X[i,node[\"i\"]] <= node[\"v\"]:\n",
    "                        node = node[\"childLeft\"]\n",
    "                    else:\n",
    "                        node = node[\"childRight\"]\n",
    "            y[i] = node[\"label\"]\n",
    "        # Return prediction classes, for example 0 or 1\n",
    "        return y\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        n_row = X.shape[0]\n",
    "        probas = np.full((n_row,2), -1)\n",
    "        for i in range(n_row):\n",
    "            # search the tree until we find a leaf node\n",
    "            node = self.root\n",
    "            while isinstance(node.get(\"v\"), (int, float)):\n",
    "                if node[\"type\"] == \"discrete\":\n",
    "                    if X[i,node[\"i\"]] == node[\"v\"]:\n",
    "                        node = node[\"childLeft\"]\n",
    "                    else:\n",
    "                        node = node[\"childRight\"]\n",
    "\n",
    "                elif node[\"type\"] == \"continuous\":\n",
    "                    if X[i,node[\"i\"]] <= node[\"v\"]:\n",
    "                        node = node[\"childLeft\"]\n",
    "                    else:\n",
    "                        node = node[\"childRight\"]\n",
    "            probas[i][0] = node[\"proba\"][0]\n",
    "            probas[i][1] = node[\"proba\"][1]\n",
    "        # Return prediction probabilities of occurrence class 0 or 1, for example 0,238 and 0,762\n",
    "        return probas\n",
    "\n",
    "    def HDDT_func(self, X, y, C):\n",
    "        \"\"\"\n",
    "        HDDT function to create and use Hellinger distance decision tree (HDDT). It is a recursive function that calls itself with subsets of training data that matches the decision criterion using a list to create the tree structure.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples, )\n",
    "            Classes/labels\n",
    "        C : integer\n",
    "            Minimum size of the training set at a node to attempt a split. Size of cut-off.\n",
    "        labels : array-like, optional\n",
    "            The default is None.\n",
    "        Returns\n",
    "        -------\n",
    "        node : tuple\n",
    "            The root node of the deicison tree\n",
    "        \"\"\"\n",
    "\n",
    "        # Node of the tree. When called for the first time, this will be the root\n",
    "        node = {}\n",
    "        node[\"C\"] = C\n",
    "        node[\"labels\"] = self.labels\n",
    "\n",
    "        # If there is only one class, this is leaf\n",
    "        if len(np.unique(y)) == 1:\n",
    "            node[\"label\"] = y[0]\n",
    "            if y[0] == 0:\n",
    "                node[\"proba\"] = [1, 0]\n",
    "            else:\n",
    "                node[\"proba\"] = [0, 1]\n",
    "            return node\n",
    "\n",
    "        # If y is smaller than minimum size of the training set, this is leaf\n",
    "        elif len(y) < C:\n",
    "            # Count number of samples of every class\n",
    "            classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "            # Use Laplace smoothing, by adding 1 to count of each class\n",
    "            counts[0] += 1\n",
    "            counts[1] += 1\n",
    "\n",
    "            # Count probabilities of every class\n",
    "            p = counts[0] / len(y)\n",
    "            if classes[0] == 0:\n",
    "                node[\"proba\"] = [p, 1-p]\n",
    "            else:\n",
    "                node[\"proba\"] = [1-p, p]\n",
    "\n",
    "            # Return label of that class(0 or 1), where there is more samples\n",
    "            if counts[0] > counts[1]:\n",
    "                node[\"label\"] = classes[0]\n",
    "            else:\n",
    "                node[\"label\"] = classes[1]\n",
    "            return node\n",
    "\n",
    "        # this is node\n",
    "        else:\n",
    "            # HD is 2D-array, it contains Hellinger Distance, value (place of split) and type (discrete or continuous)\n",
    "            HD = []\n",
    "            # hd contains only Hellinger Distance\n",
    "            hd = []\n",
    "            # Use function HDDT_dist in a recursive way\n",
    "            for i in range(self.n_features):\n",
    "                hel_dist = self.HDDT_dist(X[:,i], y, self.features_type[i])\n",
    "                HD.append(hel_dist)\n",
    "                hd.append(hel_dist[0])\n",
    "\n",
    "            i  = np.argmax(hd)\n",
    "\n",
    "            # Save node attributes\n",
    "            node[\"i\"] = i       # feature\n",
    "            node[\"d\"] = HD[i][0]\n",
    "            node[\"v\"] = HD[i][1]\n",
    "            node[\"type\"] = HD[i][2]\n",
    "\n",
    "            if node[\"type\"] == \"discrete\":\n",
    "                # j contains True and False values, True is when sample in X is equal v\n",
    "                j = np.array((X[:,i] == node[\"v\"]))\n",
    "                node[\"childLeft\"] = self.HDDT_func(X[j,:], y[j], C)\n",
    "                opposite_j = [operator.not_(value_j) for value_j in j]\n",
    "                node[\"childRight\"] = self.HDDT_func(X[opposite_j,:], y[opposite_j], C)\n",
    "\n",
    "            elif node[\"type\"] == \"continuous\":\n",
    "                # j contains True and False values, True is when sample in X is lower or equal v\n",
    "                j = np.array((X[:,i] <= node[\"v\"]))\n",
    "                node[\"childLeft\"] = self.HDDT_func(X[j,:], y[j], C)\n",
    "                opposite_j = [operator.not_(value_j) for value_j in j]\n",
    "                node[\"childRight\"] = self.HDDT_func(X[opposite_j,:], y[opposite_j], C)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def HDDT_dist(self, f, y, f_type):\n",
    "\n",
    "        \"\"\"\n",
    "        Calculate Hellinger distance for a given feature vector.\n",
    "        Attributes can be discrete or continuous.\n",
    "        It returns Hellinger distance, \"value\" of the feature that is used as decision criterion (splitting) and type of feature (discrete or continuous).\n",
    "        It works ONLY for binary labels.\n",
    "        \"\"\"\n",
    "\n",
    "        # Count number of samples of every class\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        hellinger = -1\n",
    "        # Number of samples for each class\n",
    "        T0 = counts[0]\n",
    "        T1 = counts[1]\n",
    "        val = 0\n",
    "\n",
    "        cl = f_type\n",
    "\n",
    "        # Check if the feature is discrete or continuous\n",
    "        if cl == \"discrete\":\n",
    "            for v in np.unique(f):\n",
    "\n",
    "                # Number of class 0 and class1 of value v in f (features)\n",
    "                v_index = np.argwhere(f==v).ravel()\n",
    "                Tfv1 = len(np.argwhere(y[v_index]==classes[1]).ravel())\n",
    "                Tfv0 = len(np.argwhere(y[v_index]==classes[0]).ravel())\n",
    "\n",
    "                Tfw1 = T1 - Tfv1\n",
    "                Tfw0 = T0 - Tfv0\n",
    "\n",
    "                # Calculate Hellinger distance\n",
    "                cur_value = (sqrt(Tfv1/T1) - sqrt(Tfv0/T0))**2 + (sqrt(Tfw1/T1) - sqrt(Tfw0/T0))**2\n",
    "\n",
    "                if cur_value > hellinger:\n",
    "                    hellinger = cur_value\n",
    "                    val = v\n",
    "\n",
    "        elif cl == \"continuous\":\n",
    "            for v in np.unique(f):\n",
    "                v_index = np.argwhere(f<=v).ravel()\n",
    "                Tfv1 = len(np.argwhere(y[v_index]==classes[1]).ravel())\n",
    "                Tfv0 = len(np.argwhere(y[v_index]==classes[0]).ravel())\n",
    "                Tfw1 = T1 - Tfv1\n",
    "                Tfw0 = T0 - Tfv0\n",
    "\n",
    "                # Calculate Hellinger distance\n",
    "                cur_value = (sqrt(Tfv1/T1) - sqrt(Tfv0/T0))**2 + (sqrt(Tfw1/T1) - sqrt(Tfw0/T0))**2\n",
    "\n",
    "                if cur_value > hellinger:\n",
    "                    hellinger = cur_value\n",
    "                    val = v\n",
    "        # return 3 values in tuple (Hellinger distance, value of split, type of the feature)\n",
    "        return (sqrt(hellinger), val, cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyEmsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tcc_easyemsemble():\n",
    "    def __init__(self, dataframe : pd.DataFrame, target: str, metric : str = 'average_precision', pipe_final : sklearn.pipeline = None):\n",
    "        self.dataframe = dataframe\n",
    "        self.target = target\n",
    "        self.metric = metric\n",
    "        self._pipe_final = pipe_final\n",
    "    \n",
    "    def fit(self):\n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)\n",
    "    \n",
    "        prep_feat_tuple = create_prep_pipe(self.dataframe, self.target)\n",
    "        prep_feat = prep_feat_tuple[0]\n",
    "    \n",
    "        lists_pandarizer = list(prep_feat_tuple[1]) + list(prep_feat_tuple[2])\n",
    "        \n",
    "        pipe_prep = Pipeline([\n",
    "            ('transformer_prep', prep_feat),\n",
    "            (\"pandarizer\", FunctionTransformer(lambda x: pd.DataFrame(x, columns = lists_pandarizer))),\n",
    "        ])\n",
    "        pipe_prep.fit(X_train)       \n",
    "        \n",
    "        cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.3, random_state = 42)\n",
    "        \n",
    "        metric = self.metric\n",
    "        \n",
    "        ## AdaBoost\n",
    "\n",
    "        ADA = AdaBoostClassifier(random_state = 42)\n",
    "\n",
    "        pipe_tuning = Pipeline([\n",
    "            ('transformer_prep', prep_feat),\n",
    "            (\"pandarizer\", FunctionTransformer(lambda x: pd.DataFrame(x, columns = lists_pandarizer))),\n",
    "            ('estimator', ADA)\n",
    "        ])        \n",
    "        \n",
    "        fit_params = {\n",
    "            'eval_metric': metric, \n",
    "            'eval_set': [(X_test, pd.DataFrame(y_test))],\n",
    "            'callbacks': [(early_stopping(stopping_rounds = 10, verbose = True))],\n",
    "        }        \n",
    "        \n",
    "        ADA_search_space = {\n",
    "            \"estimator__n_estimators\": Integer(100, 1000),   \n",
    "            \"estimator__learning_rate\": Real(0.001, 0.01, prior = 'log-uniform'),\n",
    "            \"estimator__algorithm\": Categorical(['SAMME', 'SAMME.R'])\n",
    "      }    \n",
    "        \n",
    "        ADA_bayes_search = BayesSearchCV(pipe_tuning, ADA_search_space, n_iter = 2, scoring = metric, \n",
    "                                         return_train_score = True, \n",
    "                                         fit_params = fit_params,\n",
    "                                         n_jobs = -1, cv = cv, random_state = 42, optimizer_kwargs = {'base_estimator': 'GP'})\n",
    "        \n",
    "        \n",
    "        ADA_bayes_search.fit(X_train, y_train)        \n",
    "        \n",
    "        results_cv = pd.DataFrame(ADA_bayes_search.cv_results_)\n",
    "        \n",
    "        temp = results_cv[['mean_train_score', 'mean_test_score']]\n",
    "        temp['diff'] = temp['mean_test_score'] - temp['mean_train_score']\n",
    "        to_go = temp[abs(temp['diff']) < 0.2].sort_values(by = 'mean_test_score', ascending = False).head(1).index\n",
    "        \n",
    "        params = results_cv.loc[to_go.values[0]]\n",
    "        kwargs = params.params   \n",
    "        kwargs = collections.OrderedDict((key.replace('estimator__', ''), value) for key, value in kwargs.items())\n",
    "        print(kwargs)\n",
    "        \n",
    "        best_ADA = AdaBoostClassifier(random_state = 42, **kwargs)\n",
    "        \n",
    "        ## EasyEmsemble \n",
    "\n",
    "        \n",
    "        EASY = EasyEnsembleClassifier(random_state = 42, base_estimator = best_ADA)\n",
    "\n",
    "        pipe_tuning = Pipeline([\n",
    "            ('transformer_prep', prep_feat),\n",
    "            (\"pandarizer\", FunctionTransformer(lambda x: pd.DataFrame(x, columns = lists_pandarizer))),\n",
    "            ('estimator', EASY)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        fit_params = {\n",
    "            'eval_metric': metric, \n",
    "            'eval_set': [(X_test, pd.DataFrame(y_test))],\n",
    "            'callbacks': [(early_stopping(stopping_rounds = 10, verbose = True))],\n",
    "        }        \n",
    "        \n",
    "        EASY_search_space = {\n",
    "            \"estimator__n_estimators\": Integer(100, 1000),\n",
    "            \"estimator__warm_start\": Categorical([True, False]),\n",
    "            \"estimator__sampling_strategy\": Categorical(['majority', 'all']),\n",
    "            \"estimator__replacement\": Categorical([True, False])\n",
    "        }    \n",
    "        \n",
    "        print('chegamos aqui')\n",
    "        EASY_bayes_search = BayesSearchCV(pipe_tuning, EASY_search_space, n_iter = 2, scoring = metric, \n",
    "                                         return_train_score = True, \n",
    "                                         fit_params = fit_params,\n",
    "                                         n_jobs = -1, cv = cv, random_state = 42, optimizer_kwargs = {'base_estimator': 'GP'})\n",
    "        \n",
    "        \n",
    "        EASY_bayes_search.fit(X_train, y_train)        \n",
    "        \n",
    "        results_cv = pd.DataFrame(EASY_bayes_search.cv_results_)\n",
    "        \n",
    "        temp = results_cv[['mean_train_score', 'mean_test_score']]\n",
    "        temp['diff'] = temp['mean_test_score'] - temp['mean_train_score']\n",
    "        to_go = temp[abs(temp['diff']) < 0.2].sort_values(by = 'mean_test_score', ascending = False).head(1).index\n",
    "        \n",
    "        params = results_cv.loc[to_go.values[0]]\n",
    "        kwargs = params.params   \n",
    "        kwargs = collections.OrderedDict((key.replace('estimator__', ''), value) for key, value in kwargs.items())\n",
    "        print(kwargs)\n",
    "        \n",
    "        best_EASY = EasyEnsembleClassifier(random_state = 42,  base_estimator = best_ADA,  **kwargs)\n",
    "        \n",
    "        best_EASY.fit(pipe_prep.transform(X_train), y_train) \n",
    "        \n",
    "        \n",
    "        pipe_final = Pipeline(\n",
    "        [\n",
    "            ('pipe_transformer_prep', pipe_prep),\n",
    "            ('pipe_estimator', best_EASY)\n",
    "        ])       \n",
    "        \n",
    "        self._pipe_final = pipe_final\n",
    "        \n",
    "    def predict_proba(self, who : str = 'val'):\n",
    "        if self._pipe_final is None:\n",
    "            return None\n",
    "        \n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)        \n",
    "        \n",
    "        dic = {'val': X_val, \n",
    "              'test': X_test,\n",
    "              'train': X_train}\n",
    "        y_score = self._pipe_final.predict_proba(dic[who])[:,1]\n",
    "        return y_score\n",
    "    \n",
    "    def get_metric(self, who : str = 'val'):\n",
    "        if self._pipe_final is None:\n",
    "            return None\n",
    "        \n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)\n",
    "        \n",
    "        dic_x = {'val': X_val, \n",
    "              'test': X_test,\n",
    "              'train': X_train}\n",
    "\n",
    "        dic_y = {'val': y_val, \n",
    "              'test': y_test,\n",
    "              'train': y_train}\n",
    "        \n",
    "        \n",
    "        y_score = self._pipe_final.predict_proba(dic_x[who])[:,1]\n",
    "        average_precision = average_precision_score(dic_y[who], y_score)\n",
    "        return average_precision\n",
    "    \n",
    "    \n",
    "    def plot_dist(self):\n",
    "        if self._pipe_final is None:\n",
    "            return None        \n",
    "\n",
    "        X, y = splitxy(self.dataframe, self.target)\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = train_test_val(X,y)        \n",
    "        \n",
    "        y_score_train = self._pipe_final.predict_proba(X_train)[:,1]\n",
    "        y_score_val = self._pipe_final.predict_proba(X_val)[:,1]\n",
    "        \n",
    "        plot_dist(y_train, y_score_train, y_val, y_score_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mvp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_easy = tcc_easyemsemble(df_mvp.head(8000), 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_easy.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_easy._pipe_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_easy.predict_proba(who = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[temp_easy.get_metric(who = 'train'), temp_easy.get_metric(who = 'test'), temp_easy.get_metric(who = 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_easy.get_metric(who = 'train') - temp_easy.get_metric(who = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_easy.plot_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Off-Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4f9643f509de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mplot_learning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results_cv' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_learning_curve(results_cv, ylim = None, train_sizes = np.linspace(0, 63, 64)):\n",
    "    title = 'Training learning curve'\n",
    "    plt.figure(figsize = (12,8))\n",
    "    plt.title(title)\n",
    "    ylim = None\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel('Training n_iter')\n",
    "    plt.ylabel('Score - mean')\n",
    "    \n",
    "    train_scores_mean = results_cv.mean_train_score\n",
    "    train_scores_std = results_cv.std_train_score\n",
    "    test_scores_mean = results_cv.mean_test_score\n",
    "    test_scores_std = results_cv.std_test_score\n",
    "    \n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, \n",
    "                    train_scores_mean + train_scores_std, alpha = 0.1,\n",
    "                     color = 'r')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, \n",
    "                    test_scores_mean + test_scores_std, alpha = 0.1,\n",
    "                     color = 'g')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color = 'r', \n",
    "            label = 'Training Score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color = 'g', \n",
    "            label = 'Cross Validation Score')\n",
    "    \n",
    "    plt.legend(loc = 'best')\n",
    "    \n",
    "    \n",
    "plot_learning_curve(results_cv, train_sizes = np.linspace(0,31,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
